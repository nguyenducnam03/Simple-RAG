# üìò Simple RAG Project: PDF Question Answering with Nutrition Book

## üß† Overview

This is a **Retrieval-Augmented Generation (RAG)** project designed for question answering based on a **nutrition book** in PDF format. The system extracts the most relevant content from the book and uses a large language model (LLM) to generate accurate answers based on the retrieved context.

## üîç What It Does

- **Input**: A PDF book on nutrition.
- **Process**:
  1. Preprocesses the PDF and splits it into chunks.
  2. Creates vector embeddings for each chunk using an embedding model.
  3. Stores the embeddings using:
     - Dot product in-memory search
     - [ChromaDB](https://www.trychroma.com/) as a vector database.
  4. Performs similarity search using both methods.
  5. Retrieves the **top 4 most relevant pages** based on the user‚Äôs question.
  6. Uses an LLM to generate an answer grounded in the retrieved context.

- **Output**: 
  - Answer generated by the LLM.
  - The pages used to support the answer.
---

## üìÅ Project Structure

The project contains **two Jupyter notebooks**:

### 1. `rag_system.ipynb`

Handles the full RAG pipeline:
- PDF loading and preprocessing
- Text chunking
- Embedding creation
- Storage and retrieval using:
  - Dot product similarity
  - ChromaDB
- Final LLM-based answer generation

### 2. `compare_vector_search.ipynb`

Performs performance benchmarking between:
- Dot product search
- ChromaDB search
It compares response time and relevance with:
- 1,000 rows
- 10,000 rows
- 100,000 rows

This helps evaluate scalability and efficiency of the two retrieval approaches.
